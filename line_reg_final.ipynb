{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from typing import Union, Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLineReg():\n",
    "    \"\"\"\n",
    "    Линейная регрессия\n",
    "\n",
    "    Гиперпараметры:\n",
    "    ***************\n",
    "    n_iter : int, optional\n",
    "        Количество шагов градиентного спуска (default: 100)\n",
    "    learning_rate : Union[float, Callable], optional\n",
    "        Коэффициент скорости обучения градиентного спуска.\n",
    "        Если на вход пришла lambda-функция, то learning_rate вычисляется \n",
    "        на каждом шаге на основе переданной функцией (default: 0.01)\n",
    "    weights : np.ndarray, optional\n",
    "        Веса модели (default: None)\n",
    "    metric : str, optional\n",
    "        Метрика, которая будет вычисляться параллельно с функцией потерь.\n",
    "        Принимает одно из следующих значений: mae, mse, rmse, mape, r2 (default: None_\n",
    "    reg : str, optional\n",
    "        Вид регуляризации. Принимает одно из следующих значений: l1, l2, elasticnet (default: None)\n",
    "    l1_coef : float, optional\n",
    "        Коэффициент L1 регуляризации. Принимает значения от 0.0 до 1.0 (default: 0)\n",
    "    l2_coef : float, optional\n",
    "        Коэффициент L2 регуляризации. Принимает значения от 0.0 до 1.0 (default: 0)\n",
    "    sgd_sample : Union[int, float], optional\n",
    "        Количество образцов, которое будет использоваться на каждой итерации обучения.\n",
    "        Может принимать целые числа, либо дробные от 0.0 до 1.0 (default: None)\n",
    "    random_state : int, optional\n",
    "        Сид для воспроизводимости результата (default: 42)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                n_iter: int = 100,\n",
    "                learning_rate: Union[float, Callable] = 0.01,\n",
    "                weights: np.ndarray = None,\n",
    "                metric: str = None,\n",
    "                reg: str = None,\n",
    "                l1_coef: float = 0,\n",
    "                l2_coef: float = 0,\n",
    "                sgd_sample: Union[int, float] = None,\n",
    "                random_state: int = 42):\n",
    "        self.n_iter = n_iter\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weights = weights\n",
    "        self.metric = metric\n",
    "        self.score = None\n",
    "        self.reg = reg\n",
    "        self.l1_coef = l1_coef\n",
    "        self.l2_coef = l2_coef\n",
    "        self.sgd_sample = sgd_sample\n",
    "        self.random_state = random_state\n",
    "\n",
    "\n",
    "    def __str__(self):\n",
    "        params = [f'{k}={v}' for k,v in self.__dict__.items()]\n",
    "        return 'MyLineReg class: ' + ', '.join(params)\n",
    "\n",
    "\n",
    "    __repr__ = __str__\n",
    "\n",
    "    @staticmethod\n",
    "    def mae(y_true: pd.Series, y_pred: pd.Series) -> float:\n",
    "        \"\"\"Средняя абсолютная ошибка\"\"\"\n",
    "        return (y_true - y_pred).abs().mean()\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def mse(y_true: pd.Series, y_pred: pd.Series) -> float:\n",
    "        \"\"\"Среднеквадратичная ошибка\"\"\"\n",
    "        return ((y_true - y_pred)**2).mean()\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def rmse(y_true: pd.Series, y_pred: pd.Series) -> float:\n",
    "        \"\"\"Квадратный корень из среднеквадратичной ошибки.\"\"\"\n",
    "        return np.sqrt(((y_true - y_pred)**2).mean())\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def r2(y_true: pd.Series, y_pred: pd.Series) -> float:\n",
    "        \"\"\"Коэффициент детерминации\"\"\"\n",
    "        return 1 - ((y_true - y_pred)**2).mean() / ((y_true - y_true.mean())**2).mean()\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def mape(y_true: pd.Series, y_pred: pd.Series) -> float:\n",
    "        \"\"\"Средняя абсолютная ошибка в процентах \"\"\"\n",
    "        return 100 * ((y_true - y_pred) / y_true).abs().mean()\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def get_metric_score(y_true: pd.Series, y_pred: pd.Series, metric: str):\n",
    "        \"\"\" \n",
    "        Подсчет выбранной метрики\n",
    "        \"\"\"\n",
    "        if metric == 'mae':\n",
    "            return MyLineReg.mae(y_true, y_pred)\n",
    "        elif metric == 'mse':\n",
    "            return MyLineReg.mse(y_true, y_pred)\n",
    "        elif metric == 'rmse':\n",
    "            return MyLineReg.rmse(y_true, y_pred)\n",
    "        elif metric == 'r2':\n",
    "            return MyLineReg.r2(y_true, y_pred)\n",
    "        elif metric == 'mape':\n",
    "            return MyLineReg.mape(y_true, y_pred)\n",
    "        else:\n",
    "            ValueError(\"Wrong metric name\")\n",
    "\n",
    "\n",
    "    def loss(self, y_true: pd.Series, y_pred: pd.Series) -> float:\n",
    "        \"\"\"\n",
    "        Подсчет значения функции потерь (MSE) \n",
    "        \"\"\"\n",
    "        loss = ((y_true - y_pred)**2).mean()\n",
    "        if self.reg == 'l1':\n",
    "            loss += self.l1_coef * np.abs(self.weights).sum()\n",
    "        elif self.reg == 'l2':\n",
    "            loss += self.l2_coef * np.square(self.weights).sum()\n",
    "        elif self.reg == 'elasticnet':\n",
    "            loss += self.l1_coef * np.abs(self.weights).sum() + self.l2_coef * np.square(self.weights).sum()\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def gradient(self, X: pd.DataFrame, y_true: pd.Series, y_pred: np.ndarray, batch_idx: list) -> float:\n",
    "        \"\"\"\n",
    "        Подсчет градиента для очередного приближения с учетом регуляризации\n",
    "        \"\"\"\n",
    "        y_true = y_true.iloc[batch_idx]\n",
    "        y_pred = y_pred[batch_idx]\n",
    "        X = X.iloc[batch_idx]\n",
    "\n",
    "        gradient = 2 / len(y_true) * np.dot((y_pred - y_true), X)\n",
    "\n",
    "        if self.reg == 'l1':\n",
    "            gradient += self.l1_coef * np.sign(self.weights)\n",
    "        elif self.reg == 'l2':\n",
    "            gradient += self.l2_coef * 2 * self.weights\n",
    "        elif self.reg == 'elasticnet':\n",
    "            gradient += self.l1_coef * np.sign(self.weights) + self.l2_coef * 2 * self.weights \n",
    "\n",
    "        return gradient\n",
    "\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series, verbose: int = False):\n",
    "        \"\"\"\n",
    "        Обучение линейной регрессии\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pd.DataFrame\n",
    "            Все фичи\n",
    "        y : pd.Series\n",
    "            Целевая переменная\n",
    "        verbose : int, optional\n",
    "            Указывает через сколько итераций градиентного спуска будет выводиться лог\n",
    "        \"\"\"\n",
    "        random.seed(self.random_state)\n",
    "        features = X.copy()\n",
    "        features.insert(loc=0, column='x0', value=1)\n",
    "        self.weights = np.ones(features.shape[1])\n",
    "\n",
    "        for i in range(1, self.n_iter + 1):\n",
    "            if isinstance(self.sgd_sample, int):\n",
    "                batch_idx = random.sample(range(features.shape[0]), self.sgd_sample)\n",
    "            elif isinstance(self.sgd_sample, float):\n",
    "                batch_idx = random.sample(range(features.shape[0]), int(features.shape[0] * self.sgd_sample))\n",
    "            else:\n",
    "                batch_idx = list(range(features.shape[0]))\n",
    "            \n",
    "            y_pred = np.dot(features, self.weights)\n",
    "            loss = self.loss(y, y_pred)\n",
    "            gradient = self.gradient(features, y, y_pred, batch_idx)\n",
    "\n",
    "            if callable(self.learning_rate):\n",
    "                self.weights -= self.learning_rate(i) * gradient\n",
    "            else:\n",
    "                self.weights -= self.learning_rate * gradient\n",
    "            self.score = MyLineReg.get_metric_score(y, self.predict(X), self.metric)\n",
    "\n",
    "            if verbose:\n",
    "                if (i == 1) or (i % verbose == 0):\n",
    "                    log = f'{i} | loss: {loss}'\n",
    "                    if self.metric:\n",
    "                        log += f' | metric: {MyLineReg.get_metric_score(y, y_pred, self.metric)}'\n",
    "                    print(log)\n",
    "\n",
    "\n",
    "    def predict(self, X: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Выдача предсказаний моделью\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pd.DataFrame\n",
    "            Матрица фичей\n",
    "        \"\"\"\n",
    "        features = X.copy()\n",
    "        features.insert(loc=0, column='x0', value=1)\n",
    "        y_pred = np.dot(features, self.weights)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "    def get_coef(self):\n",
    "        return self.weights[1:]\n",
    "\n",
    "\n",
    "    def get_best_score(self):\n",
    "        return self.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyLineReg class: n_iter=100, learning_rate=0.01, weights=None, metric=None, score=None, reg=None, l1_coef=0, l2_coef=0, sgd_sample=None, random_state=42"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MyLineReg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X, y = make_regression(n_samples=1000, n_features=14, n_informative=10, noise=15, random_state=42)\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.Series(y)\n",
    "X.columns = [f'col_{col}' for col in X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9894838065073632"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "model = MyLineReg(n_iter=50, learning_rate=0.1, metric='r2', reg ='l1', l1_coef=0.1, sgd_sample = 0.2)\n",
    "\n",
    "model.fit(X,y)\n",
    "predictions = model.predict(X)\n",
    "\n",
    "r2_score(y, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
